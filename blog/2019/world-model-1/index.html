<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 世界模型（一）：记忆、感知、预测、评估、决策的联合 | Siyuan Liang </title> <meta name="author" content="Siyuan Liang"> <meta name="description" content="区分“模拟世界”与“理解世界”，阐述世界模型五大模块的统一可微框架，并讨论空间智能、抽象学习与长期记忆等前沿方向。"> <meta name="keywords" content="long-context-modeling, recurrent-architectures, deep-learning, algorithm-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://siyuanseever.github.io/blog/2019/world-model-1/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Siyuan</span> Liang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">世界模型（一）：记忆、感知、预测、评估、决策的联合</h1> <p class="post-meta"> Created on March 31, 2019 </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/agi"> <i class="fa-solid fa-hashtag fa-sm"></i> AGI</a>   <a href="/blog/tag/agent"> <i class="fa-solid fa-hashtag fa-sm"></i> Agent</a>   <a href="/blog/tag/world-model"> <i class="fa-solid fa-hashtag fa-sm"></i> World-Model</a>   <a href="/blog/tag/memory"> <i class="fa-solid fa-hashtag fa-sm"></i> Memory</a>   <a href="/blog/tag/perception"> <i class="fa-solid fa-hashtag fa-sm"></i> Perception</a>   <a href="/blog/tag/prediction"> <i class="fa-solid fa-hashtag fa-sm"></i> Prediction</a>   <a href="/blog/tag/rl"> <i class="fa-solid fa-hashtag fa-sm"></i> RL</a>   ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>本文原写于 2019 年 4 月，拟作为雷达硕士论文的一章，因精力有限搁置。2026 年 1 月重审，补入近年 LLM 与空间智能的新思考，仍愿为相关方向的同学提供一份“初心”笔记。</p> </blockquote> <p>在讨论世界模型之前，我们先区分两个概念：<strong>模拟世界（simulate）</strong> 与 <strong>理解世界（understand）</strong>。当下的视频生成模型（如 Sora、MovieGen）能在像素层面“模拟”世界，但是否真正把握了背后的物理与因果？借用物理学中的“统一场论”隐喻，我将<strong>世界模型（World Models）</strong>定义为：能够将<strong>记忆、感知、预测、评估、决策</strong>功能联合为<strong>整体可微可导</strong>闭环的模型框架。它不止于生成逼真的帧，还要构建一个能推理、能交互的“心智”。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/world_model-480.webp 480w,/assets/img/world-model/world_model-800.webp 800w,/assets/img/world-model/world_model-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/world_model.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 世界模型概念图 </div> <h2 id="一五大模块功能与形式">一、五大模块：功能与形式</h2> <h3 id="1-记忆memory">1 记忆（Memory）</h3> <p>保存并更新时序因果的内部状态，利用上一时刻记忆与当前观测共同计算当前状态与新记忆<br> \(s_t,\; m_t \;=\; D\!\big(o_t,\; m_{t-1}\big)\) 只要能保留长期记忆的时序因果模型，在结构上都属于带记忆功能。从古老的 RNN、LSTM，到近年的 RWKV、RetNet、Mamba，乃至我 2023 年手搓的 <a href="https://github.com/siyuanseever/llama2RNN.c" rel="external nofollow noopener" target="_blank">llama2RNN.c</a> 演示，都在重铸 RNN 荣光。</p> <h3 id="2-感知perception">2 感知（Perception）</h3> <p>将高维观测压缩为抽象状态，并可大致重构原始观测，类似自编码器 / MAE<br> \(\hat{o}\;=\;D^{-1}\!\big(D(o)\big)\) 其中抽象状态 $s_t = D(o_t)$ 的数据量远小于原始观测 $o_t$。</p> <h3 id="3-预测prediction">3 预测（Prediction）</h3> <p>从抽象状态出发进行<strong>下一状态预测（Next State Prediction）</strong>而非像素预测<br> \(s'_{t+1}\;=\;P(s_t)\) 现在的 LLM 大抵是 Next Token Prediction；对世界模型而言，更高效的做法是在状态空间做 Next State Prediction。</p> <h3 id="4-评估evaluation">4 评估（Evaluation）</h3> <p>对状态的“好坏”进行价值评估（价值网络）<br> \(v_t \;=\; E(s_t) \;=\; \mathbb{E}\!\left[r \;+\; \gamma\, E\!\big(s_{t+1}\big)\right]\)</p> <h3 id="5-决策decision">5 决策（Decision）</h3> <p>基于状态选择行为，影响环境与自身（策略 / 动作价值）<br> \(\pi(s) \;=\; \arg\max_{a}\, Q(s,a)\) 要点：记忆承载时序因果；感知把观测压成结构化状态；预测在状态空间演化；评估为长期目标提供回传；决策通过行动改变未来。五者的<strong>协同与可微耦合</strong>，形成“感知—预测—评估—行动—再感知”的闭环。</p> <h2 id="二从生成到交互为什么是状态预测">二、从生成到交互：为什么是“状态预测”</h2> <ul> <li>生成视频（Sora / MovieGen）强调像素细节，但过度关注纹理可能牺牲物理与因果建模的算力预算。</li> <li>交互式生成（Genie / Genie2）引入动作与环境响应，更接近世界模型本质。</li> <li>高效世界模型应工作在<strong>抽象状态空间</strong>而非像素空间（类似 JEPA 思路），用更低维、更结构化的隐状态承载动力学与因果。</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/genie3-480.webp 480w,/assets/img/world-model/genie3-800.webp 800w,/assets/img/world-model/genie3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/genie3.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 交互式生成 Genie </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/JEPA-480.webp 480w,/assets/img/world-model/JEPA-800.webp 800w,/assets/img/world-model/JEPA-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/JEPA.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> JEPA：在抽象状态空间进行预测 </div> <h2 id="三统一模型的一些例子">三、统一模型的一些例子</h2> <h3 id="1-基于端到端模仿学习的廉价机器人视觉多任务操作系统">1 基于端到端模仿学习的廉价机器人视觉多任务操作系统</h3> <p>完成了“感知—记忆—行动”的组合：控制网络输出联合命令，自编码器（VAE-GAN）作为感知模块为控制网络提供状态特征，实现端到端视觉到行为的映射。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/demonstration-480.webp 480w,/assets/img/world-model/demonstration-800.webp 800w,/assets/img/world-model/demonstration-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/demonstration.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 基于端到端模仿学习的廉价机器人视觉多任务操作系统示意 </div> <h3 id="2-next-state-prediction">2 Next State Prediction</h3> <p>如果说 LLM 的 Next Word Prediction 将预测功能发挥到极致，那么针对密集信息（如视频）的高效学习，更应在<strong>状态空间</strong>做下一状态预测。下图为一个简单的构想：结合自编码器的感知能力和自回归的预测能力。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/next_word_prediction.drawio-480.webp 480w,/assets/img/world-model/next_word_prediction.drawio-800.webp 800w,/assets/img/world-model/next_word_prediction.drawio-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/next_word_prediction.drawio.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Next State 预测构想 </div> <p>相关思路可参考：JEPA、Emu3.5 等。直观上，将“像素/词”转到“隐状态”进行预测，更接近因果与动力学的本质。</p> <h3 id="3-v-jepa-2-ac自监督视频模型实现理解预测和规划">3 V-JEPA 2-AC：自监督视频模型实现理解、预测和规划</h3> <p>在感知与预测的基础上引入动作信息，虽未直接生成行动决策，但学习“什么样的动作会演变为下一时刻的状态”，从而实现对训练数据中动作的模仿。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/V-JEPA2-AC-480.webp 480w,/assets/img/world-model/V-JEPA2-AC-800.webp 800w,/assets/img/world-model/V-JEPA2-AC-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/V-JEPA2-AC.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> V-JEPA 2-AC </div> <p>另外，针对“记忆”的长期一致性建模，可参考下图的记忆注意力思路：</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/memoryAttention-480.webp 480w,/assets/img/world-model/memoryAttention-800.webp 800w,/assets/img/world-model/memoryAttention-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/memoryAttention.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 记忆注意力（Memory Attention） </div> <h2 id="四空间智能从生成视频到生成世界">四、空间智能：从“生成视频”到“生成世界”</h2> <p>以“空间智能（Spatial Intelligence）”为例：目标是构建能<strong>感知、生成、推理、交互</strong>的 3D 世界表征。与纯视频生成不同，空间智能强调：</p> <ul> <li>空间一致性：内部具备显式、符合物理规律的 3D/隐状态表示；</li> <li>持久性：生成的不只是帧序列，而是可被存储、编辑、反复进入的<strong>持久化世界</strong>。</li> </ul> <p>这要求模型具备长期记忆与连贯推理能力，可通过 ConvLSTM、状态空间模型、或结合记忆的 Transformer/混合结构实现。</p> <blockquote> <p>Perception and action became the core loop driving the evolution of intelligence.</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/Marble-480.webp 480w,/assets/img/world-model/Marble-800.webp 800w,/assets/img/world-model/Marble-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/Marble.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Marble：从生成视频到生成世界 </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/Long-Context%20State-Space%20Video%20World%20Models-480.webp 480w,/assets/img/world-model/Long-Context%20State-Space%20Video%20World%20Models-800.webp 800w,/assets/img/world-model/Long-Context%20State-Space%20Video%20World%20Models-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/Long-Context%20State-Space%20Video%20World%20Models.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Long-Context State-Space Video World Models </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/Long-Context%20State-Space%20Model%20architecture-480.webp 480w,/assets/img/world-model/Long-Context%20State-Space%20Model%20architecture-800.webp 800w,/assets/img/world-model/Long-Context%20State-Space%20Model%20architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/Long-Context%20State-Space%20Model%20architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Long-Context State-Space Model 架构 </div> <h2 id="五像人类一样学习抽象持续与时间">五、像人类一样学习：抽象、持续与时间</h2> <ul> <li>抽象学习：更多依赖空间常识与抽象概念，而非逐像素/逐词的死记硬背。</li> <li>持续学习：从“通用”走向“进化”，在交互中不断适应与改进自身。</li> <li>时间感知：结构上具备“对时间敏感”的归纳偏置（如带记忆的序列结构），才能理解熵增与因果，并形成真正的长期经验积累。</li> </ul> <p>进一步地，通过带记忆的架构，模型具备<strong>时序因果的长期记忆</strong>，不仅可解决“长度外推”，更能在单向时间流中积累经验，而非每次重启都被“格式化”。</p> <h2 id="六实践案例预告智能电磁博弈">六、实践案例预告：智能电磁博弈</h2> <p>为验证框架的通用性，下一篇展示<strong>智能电磁博弈</strong>案例：以 ConvLSTM 等结构承载长期记忆，通过策略与价值网络形成端到端可微闭环，让“发射波形—环境干扰—回波检测—价值评估—策略更新”在同一链路中共同优化。</p> <hr> <h2 id="参考与延伸">参考与延伸</h2> <ul> <li>llama2RNN.c demo: <a href="https://github.com/siyuanseever/llama2RNN.c" rel="external nofollow noopener" target="_blank">https://github.com/siyuanseever/llama2RNN.c</a> </li> <li>零碎介绍： <a href="https://zhuanlan.zhihu.com/p/681684286" rel="external nofollow noopener" target="_blank">https://zhuanlan.zhihu.com/p/681684286</a> </li> <li>World Model 讨论与资料： <ul> <li><a href="https://www.xunhuang.me/blogs/world_model.html" rel="external nofollow noopener" target="_blank">https://www.xunhuang.me/blogs/world_model.html</a></li> <li><a href="https://leshouches2022.github.io/SLIDES/compressed-yann-1.pdf" rel="external nofollow noopener" target="_blank">https://leshouches2022.github.io/SLIDES/compressed-yann-1.pdf</a></li> <li><a href="https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence" rel="external nofollow noopener" target="_blank">https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence</a></li> <li><a href="https://www.worldlabs.ai/blog/marble-world-model" rel="external nofollow noopener" target="_blank">https://www.worldlabs.ai/blog/marble-world-model</a></li> </ul> </li> </ul> <hr> <p>系列导航</p> <ul> <li>下一篇：<a href="/blog/2019/intelligent-radar/">世界模型（二）：智能电磁博弈</a> </li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/intelligent-radar/">世界模型（二）：智能电磁博弈</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/intelligent-radar-en/">World Models (II): Intelligent Electromagnetic Game</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Siyuan Liang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>