<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 世界模型（一）：记忆、感知、预测、评估、决策的联合 | Siyuan Liang </title> <meta name="author" content="Siyuan Liang"> <meta name="description" content="区分“模拟世界”与“理解世界”，阐述世界模型五大模块的统一可微框架，并讨论空间智能、抽象学习与长期记忆等前沿方向。"> <meta name="keywords" content="long-context-modeling, recurrent-architectures, deep-learning, algorithm-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://siyuanseever.github.io/blog/2019/world-model-1/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Siyuan</span> Liang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">世界模型（一）：记忆、感知、预测、评估、决策的联合</h1> <p class="post-meta"> Created on March 31, 2019 </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/agi"> <i class="fa-solid fa-hashtag fa-sm"></i> AGI</a>   <a href="/blog/tag/agent"> <i class="fa-solid fa-hashtag fa-sm"></i> Agent</a>   <a href="/blog/tag/world-model"> <i class="fa-solid fa-hashtag fa-sm"></i> World-Model</a>   <a href="/blog/tag/memory"> <i class="fa-solid fa-hashtag fa-sm"></i> Memory</a>   <a href="/blog/tag/perception"> <i class="fa-solid fa-hashtag fa-sm"></i> Perception</a>   <a href="/blog/tag/prediction"> <i class="fa-solid fa-hashtag fa-sm"></i> Prediction</a>   <a href="/blog/tag/rl"> <i class="fa-solid fa-hashtag fa-sm"></i> RL</a>   ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>本文原写于 2019 年 4 月，拟作为雷达硕士论文的一章，因精力有限搁置。2026 年 1 月重审，补入近年 LLM 与空间智能的新思考，仍愿为相关方向的同学提供一份“初心”笔记。</p> </blockquote> <p>在讨论世界模型之前，我们先区分两个概念：<strong>模拟世界（simulate）</strong> 与 <strong>理解世界（understand）</strong>。当下的视频生成模型（如 Sora、MovieGen）能在像素层面“模拟”世界，但是否真正把握了背后的物理与因果？借用物理学中的“统一场论”隐喻，我将<strong>世界模型（World Models）</strong>定义为：能够将<strong>记忆、感知、预测、评估、决策</strong>功能联合为<strong>整体可微可导</strong>闭环的模型框架。它不止于生成逼真的帧，还要构建一个能推理、能交互的“心智”。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/world_model-480.webp 480w,/assets/img/world-model/world_model-800.webp 800w,/assets/img/world-model/world_model-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/world_model.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 世界模型概念图 </div> <h2 id="前言">前言</h2> <p>这里其实是借鉴物理学中统一场论的概念：一个可以统一四种基本力的物理理论。</p> <blockquote> <p><strong>统一模型是指一个能够把记忆、感知、预测、评估、决策功能联合为整体可微可导的模型框架。</strong></p> </blockquote> <p>下面我会详细说明这些功能的具体内容以及如何将它们“有机”（可微可导）地结合在一起。后续章节则尝试在具体任务中构建它们。</p> <h2 id="多种功能的具体介绍">多种功能的具体介绍</h2> <p>首先我们对智能体给出这样的描述，智能体应该拥有如下几个功能：</p> <ul> <li>记忆功能</li> <li>感知功能</li> <li>预测功能</li> <li>评估功能</li> <li>行动功能</li> </ul> <p>下面将逐一介绍这些功能。</p> <h3 id="记忆功能">记忆功能</h3> <blockquote> <p>记忆能力并不是指能够记录信息，而是要能够利用上一时刻的记忆信息和当前时刻的观测信息共同完成信息处理（包括但不限于信息的感知、预测、评估、决策）和当前时刻的记忆形成。以信息感知为例：</p> </blockquote> \[s_t,\; m_t \;=\; D\!\big(o_t,\; m_{t-1}\big)\] <p>其中 $D$ 为感知系统，$o$ 为观测信息，$s$ 为感知得到的状态信息，$m$ 便是记忆信息。</p> <p>其实只要能保留长期记忆的时序因果模型在结构上都属于带记忆功能的，这部分比较古老的框架如 RNN、LSTM；最近几年也重新兴起了重铸 RNN 荣光的事情，也就是将 RNN 与 Transformer 相结合，如 RWKV、RetNet 等。我在 2023 年也兴致勃勃地构建了 <a href="https://github.com/siyuanseever/llama2RNN.c" rel="external nofollow noopener" target="_blank">llama2RNN.c</a> 的 demo（可下载），<a href="https://zhuanlan.zhihu.com/p/681684286" rel="external nofollow noopener" target="_blank">这里</a> 是一些零碎的介绍，后续会整理成长文。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/memoryAttention-480.webp 480w,/assets/img/world-model/memoryAttention-800.webp 800w,/assets/img/world-model/memoryAttention-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/memoryAttention.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 记忆注意力（Memory Attention） </div> <h3 id="感知功能">感知功能</h3> <blockquote> <p>感知能力是指系统能够将观测信息进行压缩理解，得到抽象概念，并根据抽象概念大致还原出原始信息的能力：</p> </blockquote> \[\hat{o}\;=\;D^{-1}\!\big(D(o)\big)\] <p>其中 $D^{-1}$ 为 $D$ 的逆处理系统，得到的抽象概念 $D(o)$ 的数据大小要远小于观测信息 $o$ 的数据大小。</p> <p>这里比较简单的自编码器就可以完成感知任务了，MAE 也大致可以算作这个思路。</p> <h3 id="预测功能">预测功能</h3> <blockquote> <p>预测能力是指系统能够根据上一时刻从感知系统中得到的状态信息（以及其它能够获取的先验信息）预测下一时刻的状态信息：</p> </blockquote> \[s'_{t+1}\;=\;P(s_t)\] <p>其中 $P$ 为预测系统。</p> <p>现在的 LLM 大抵就是这么学习的了，不过它们不是针对状态预测，而是直接对原始信息（仅仅简单的做了下压缩分词变成 Token）做预测。</p> <h3 id="评估功能">评估功能</h3> <blockquote> <p>评估能力是指系统能够对给定的状态做出价值评估，估计出自身状态的好坏，用一个单值表示：</p> </blockquote> \[v_t \;=\; E(s_t) \;=\; \mathbb{E}\!\left[r \;+\; \gamma\, E\!\big(s_{t+1}\big)\right]\] <p>其中 $E$ 为评估系统，$v$ 为给定状态 $s$ 下的评估价值，该评估值与系统自身接收的真实奖励 $r$ 以及未来奖励 $E(s_{t+1})$ 有关。</p> <h3 id="决策功能">决策功能</h3> <blockquote> <p>行动能力是指系统可以根据状态信息作出行动决策，该行动能够改变环境和自身状态及价值：</p> </blockquote> \[\pi(s) \;=\; \arg\max_{a}\, Q(s, a)\] <p>这里的重点是能够改变环境和自身状态的行动才是有效的行动，需要注意。其中 $\pi$ 为决策系统，$a$ 为决策系统给出的有效行动，$Q$ 为动作价值函数。决策不仅包括对外部环境和自身状态的改变，甚至是对自身网络结构（完成类似 2019 年比较火的模型架构搜索相关的功能，如 NASNet）和训练过程的改变和控制，指系统能够利用所有可用资源不断地改善智能体的各种功能的效果，也就是系统拥有“自我学习能力”。</p> <h2 id="统一模型的一些例子">统一模型的一些例子</h2> <h3 id="基于端到端模仿学习的廉价机器人视觉多任务操作系统">基于端到端模仿学习的廉价机器人视觉多任务操作系统</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/demonstration-480.webp 480w,/assets/img/world-model/demonstration-800.webp 800w,/assets/img/world-model/demonstration-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/demonstration.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 基于端到端模仿学习的廉价机器人视觉多任务操作系统示意 </div> <p>上图为一个基于端到端模仿学习的廉价机器人视觉多任务操作系统（Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration），完成了上述的感知、记忆、行动功能的组合。系统包含一个基于多模式自回归估计的输出联合命令的控制网络，和一个重构图片的 VAE-GAN 自编码器，其中编码器（感知系统）为控制网络提供状态特征信息。</p> <h3 id="next-state-prediction">Next State prediction</h3> <p>如果说 LLM 的 Next World prediction 是一个将预测功能发挥到极致效果的表现，那 Next State prediction 就是将预测与感知相结合，来解决信息量密集型数据（如图像）的高效学习。类似于现在我们已经完成了对互联网全部文本数据的学习，但就算是文本也可以用隐层状态预测来极大地提高效率。</p> <p>下面是我针对视频预测的一个简单构想的框架示意图：</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/next_word_prediction.drawio-480.webp 480w,/assets/img/world-model/next_word_prediction.drawio-800.webp 800w,/assets/img/world-model/next_word_prediction.drawio-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/next_word_prediction.drawio.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Next State 预测构想 </div> <p>这个构想非常简单直接，就是结合自编码器的感知能力和自回归模型的预测能力，所以有很多相似的想法可以参考：</p> <ul> <li>Joint Embedding Predictive Architecture（JEPA）</li> <li>Emu3.5（我都想入职了：）</li> </ul> <p>by the way, 感觉自己很多思路和出发点都能在 LeCun 老爷子的世界模型那里获得认同感（见“通往自主机器智能的道路”），而且我也同样没有能力把想法给工程化：）。</p> <h3 id="v-jepa-2-ac自监督视频模型实现理解预测和规划">V-JEPA 2-AC：自监督视频模型实现理解、预测和规划</h3> <p>这里在感知和预测的基础上，增加了决策的影响，虽然不是直接给出行动（这可能还需要评估模块的引入以及强化学习，我将在下一篇博客中具体介绍：），而是有监督的学习什么样的动作会演变为下一时刻的状态。所以最终实现了对训练数据中动作的简单模仿：）（如果有误，欢迎指正）。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/V-JEPA2-AC-480.webp 480w,/assets/img/world-model/V-JEPA2-AC-800.webp 800w,/assets/img/world-model/V-JEPA2-AC-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/V-JEPA2-AC.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> V-JEPA 2-AC </div> <h2 id="前沿方向空间智能-spatial-intelligence">前沿方向：空间智能 (Spatial Intelligence)</h2> <p>斯坦福李飞飞教授团队（World Labs）最近提出的<strong>空间智能 (Spatial Intelligence)</strong> 概念，为世界模型提供了一个极佳的落地场景。</p> <h3 id="1-视觉--语言">1. 视觉 &gt; 语言？</h3> <p>李飞飞教授指出，相比于语言，<strong>视觉（Vision）</strong> 是更为基础的生物本能。</p> <blockquote> <p>Perception and action became the core loop driving the evolution of intelligence.</p> </blockquote> <p>从寒武纪大爆发开始，<strong>“感知-行动”</strong> 的循环就是推动智能进化的核心动力。没有语言的动物依然可以通过视觉理解物理世界的规则（如重力、空间遮挡）并做出决策。因此，构建 AGI 的下一步，不应仅仅局限于 LLM 的文本逻辑，更需要让 AI 拥有<strong>“空间认知”</strong> 能力。</p> <h3 id="2-核心定义">2. 核心定义</h3> <p>她定义的空间智能模型需要具备：</p> <blockquote> <p>building frontier models that can perceive, generate, reason, and interact with the 3D world.</p> </blockquote> <p>这与我上述的“五位一体”定义不谋而合：</p> <ul> <li> <strong>Perceive (感知)</strong>：理解 3D 空间结构。</li> <li> <strong>Generate (预测/生成)</strong>：想象未来的可能性。</li> <li> <strong>Reason (评估/记忆)</strong>：进行因果推理。</li> <li> <strong>Interact (决策)</strong>：与物理世界进行交互。</li> </ul> <h3 id="3-marble从生成视频到生成世界">3. Marble：从“生成视频”到“生成世界”</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/Marble-480.webp 480w,/assets/img/world-model/Marble-800.webp 800w,/assets/img/world-model/Marble-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/Marble.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Marble：持久化 3D 世界生成 </div> <p>World Labs 推出的首款产品 <strong>Marble</strong>，展示了空间智能与普通视频生成的关键区别：</p> <ul> <li> <strong>空间一致性 (Spatial Consistency)</strong>：Sora 等视频生成模型往往存在“空间崩坏”的问题（如人走着走着消失了，或者透视关系错误）。而空间智能要求模型内部有一个显式的、符合物理规律的 3D 表达（Hidden State）。</li> <li> <strong>持久性 (Persistence)</strong>：生成的不是稍纵即逝的像素帧，而是一个可以被存储、编辑、反复进入的<strong>持久化 3D 世界</strong>。</li> </ul> <p>这种能力让 AI 从“画师”变成了“造物主”，能够构建一个可交互的虚拟实验场。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/Long-Context_State-Space_Video_World_Models-480.webp 480w,/assets/img/world-model/Long-Context_State-Space_Video_World_Models-800.webp 800w,/assets/img/world-model/Long-Context_State-Space_Video_World_Models-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/Long-Context_State-Space_Video_World_Models.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 长时序状态空间视频世界模型 </div> <p>当然“生成视频”的路子也有解决思路，那就是引入<strong>长期记忆</strong>，从早期的 ConvLSTM，到最新的 State-Space Model，甚至我之前设计的 Block-wise Recurrent Transformer 都是要做这样的时序一致性推理。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/Long-Context_State-Space_Model_architecture-480.webp 480w,/assets/img/world-model/Long-Context_State-Space_Model_architecture-800.webp 800w,/assets/img/world-model/Long-Context_State-Space_Model_architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/Long-Context_State-Space_Model_architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 长时序状态空间模型架构 </div> <hr> <h2 id="核心特征像人类一样学习">核心特征：像人类一样学习</h2> <p>世界模型与传统深度学习系统的一个显著区别在于<strong>学习路径</strong>。现有的深度学习（DL）效率极低，依赖海量标注数据（Supervised Learning）或试错（RL）。未来十年，AI 的学习方式可能有一些本质的改变：</p> <ol> <li> <strong>抽象学习（Abstract Learning）</strong>：像人类医生看 MRI 影像一样，AI 将学会利用“空间常识”和“抽象概念”进行学习，而非死记硬背像素点或者下一个单词。</li> <li> <strong>持续学习（Continual Learning）</strong>：<strong>从“通用”到“进化”</strong>：我们不应追求一个出厂即巅峰的 AGI，而应追求像人类一样能不断适应环境、持续进化的 <strong>Evolving Intelligence</strong>。</li> <li> <strong>时间感知</strong>：现实世界中，时间的流逝是唯一的物理真理。未来的模型（无论是 CNN 还是 Transformer）最终都要加上类似 <strong>LSTM 的 RNN 体质</strong>。如果模型无法从结构上感知到时间，就无法理解熵增与因果，也就无法诞生真正的“硅基生命”。</li> </ol> <p>通过 RNN 类的架构，模型将具备<strong>时序因果的长期记忆</strong>。这不仅能解决“长度外推”问题，更能让 AI 在物理世界的单向时间流中，通过持续的 Training Step 和状态保留，像生物一样积累经验，而非每次重启都被“格式化”。</p> <hr> <h2 id="实践案例智能电磁博弈intelligent-electromagnetic-game">实践案例：智能电磁博弈（Intelligent Electromagnetic Game）</h2> <p>为了证明这个框架不仅仅适用于生成视频或玩游戏，我以一个更“硬核”的领域——<strong>雷达与干扰的博弈</strong>为例，展示世界模型是如何在信号处理领域落地的。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/world-model/intelligent_electromagnetic_game-480.webp 480w,/assets/img/world-model/intelligent_electromagnetic_game-800.webp 800w,/assets/img/world-model/intelligent_electromagnetic_game-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/world-model/intelligent_electromagnetic_game.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 智能电磁博弈示意 </div> <p>在我的硕士论文研究中，构建了一个基于深度强化学习的<strong>雷达智能体</strong>，它完整地体现了世界模型的闭环：</p> <ol> <li> <strong>感知与记忆</strong>：利用 <strong>Conv-LSTM</strong> 处理连续脉冲回波，不仅提取当前特征，还保留了历史脉冲的长期记忆。</li> <li> <strong>决策（Action）</strong>：雷达的发射波形不再是固定的，而是由策略网络 $\pi(o_{t-1})$ 根据历史观测生成的。</li> <li> <strong>评估（Value）</strong>：构建价值网络 $V(o_t)$，预测当前波形在未来对抗中的长期检测回报。</li> <li> <strong>博弈（World）</strong>：雷达与干扰机（环境）在<strong>全微分</strong>的链路中进行对抗训练。</li> </ol> <p>在这个模型中，<strong>发射波形（决策）-&gt; 环境干扰（反馈）-&gt; 回波检测（感知/评估）</strong> 形成了一个完整的端到端闭环。</p> <hr> <h2 id="结束语">结束语</h2> <p>我认为历史上众多璀璨的想法和技术，无论是强化学习、元学习、自回归预测、压缩感知等学习方式，还是 RNN、ResNet、Transformer 等具体的模型结构，亦或者是模型架构或者训练超参数搜索等等技术，它们都有自己的可取之处。我也相信未来 AGI 的构建需要这些智慧结晶，而对于现在极致工业化和商用流行的 LLM 也不会嫌弃，它们都是构成这个宏大“世界模型”拼图的一部分。</p> <hr> <p>系列导航</p> <ul> <li>下一篇：<a href="/blog/2019/intelligent-radar/">世界模型（二）：智能电磁博弈</a> </li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/intelligent-radar/">世界模型（二）：智能电磁博弈</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/intelligent-radar-en/">World Models (II): Intelligent Electromagnetic Game</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/world-model-1-en/">World Models (I): The Union of Memory, Perception, Prediction, Evaluation, and Decision</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Siyuan Liang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>